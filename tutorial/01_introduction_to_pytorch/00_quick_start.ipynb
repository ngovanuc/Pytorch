{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fea40f25",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d56df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f2fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:21<00:00, 1.25MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 143kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:04<00:00, 930kB/s] \n",
      "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"..\\\\..\\\\data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"..\\\\..\\\\data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44414b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_loader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf254ab",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542888d",
   "metadata": {},
   "source": [
    "- Để tạo model, định nghĩa một lớp kế thừa từ module nn.Module\n",
    "- Sau đó định nghĩa các layers của model bằng hàm khởi tạo __init__\n",
    "- Và định nghĩ một hàm forward để định nghĩa cách mà data đi qua model.\n",
    "- Để tăng tốc quá trình huấn luyện, sử dụng CUDA, MPS, MTIA hoặc XPU. Nếu các thứ đó không có, mặc định là sử dụng CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a08270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        \n",
    "model = NeuralNetwork().to(device=device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb044f",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca83354",
   "metadata": {},
   "source": [
    "- Để train một model, chúng ta cần hàm loss (loss function) và một trình tối ưu (opimizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b0b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af478e80",
   "metadata": {},
   "source": [
    "Trong một vòng đào tạo duy nhất, mô hình đưa ra dự đoán về tập dữ liệu đào tạo (được đưa vào theo từng đợt) và truyền ngược lỗi dự đoán để điều chỉnh các tham số của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a6b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d5147",
   "metadata": {},
   "source": [
    "Chúng ta cũng có thể kiểm tra hiệu suất của mô hình so vói tập dữ liệu thử nghiệm để đảm bảo mô hình đang học"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92b4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bc98f",
   "metadata": {},
   "source": [
    "Quá trình đào tạo được tiến hành qua nhiều lần lặp lại (epoch). Trong mỗi epoch, mô hình học các tham số để đưa ra dự đoán tốt hơn. Chúng tôi in độ chính xác và mất mát của mô hình tại mỗi epoch; chúng tôi muốn thấy độ chính xác tăng lên và mất mát giảm đi sau mỗi epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed73a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.166575 [   64/60000]\n",
      "Loss: 2.163471 [ 6464/60000]\n",
      "Loss: 2.107331 [12864/60000]\n",
      "Loss: 2.130344 [19264/60000]\n",
      "Loss: 2.079512 [25664/60000]\n",
      "Loss: 2.009227 [32064/60000]\n",
      "Loss: 2.061512 [38464/60000]\n",
      "Loss: 1.969751 [44864/60000]\n",
      "Loss: 1.977387 [51264/60000]\n",
      "Loss: 1.916028 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 53.0%, Avg loss: 1.906045 \n",
      "\n",
      "Loss: 1.931304 [   64/60000]\n",
      "Loss: 1.906060 [ 6464/60000]\n",
      "Loss: 1.794049 [12864/60000]\n",
      "Loss: 1.843705 [19264/60000]\n",
      "Loss: 1.727313 [25664/60000]\n",
      "Loss: 1.673452 [32064/60000]\n",
      "Loss: 1.720644 [38464/60000]\n",
      "Loss: 1.602671 [44864/60000]\n",
      "Loss: 1.630123 [51264/60000]\n",
      "Loss: 1.532759 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 60.3%, Avg loss: 1.538773 \n",
      "\n",
      "Loss: 1.600547 [   64/60000]\n",
      "Loss: 1.566487 [ 6464/60000]\n",
      "Loss: 1.419550 [12864/60000]\n",
      "Loss: 1.494487 [19264/60000]\n",
      "Loss: 1.368685 [25664/60000]\n",
      "Loss: 1.359783 [32064/60000]\n",
      "Loss: 1.392320 [38464/60000]\n",
      "Loss: 1.299006 [44864/60000]\n",
      "Loss: 1.334747 [51264/60000]\n",
      "Loss: 1.236593 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 63.3%, Avg loss: 1.258859 \n",
      "\n",
      "Loss: 1.333633 [   64/60000]\n",
      "Loss: 1.316381 [ 6464/60000]\n",
      "Loss: 1.154383 [12864/60000]\n",
      "Loss: 1.257018 [19264/60000]\n",
      "Loss: 1.133583 [25664/60000]\n",
      "Loss: 1.151566 [32064/60000]\n",
      "Loss: 1.188222 [38464/60000]\n",
      "Loss: 1.109020 [44864/60000]\n",
      "Loss: 1.148290 [51264/60000]\n",
      "Loss: 1.064700 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 64.6%, Avg loss: 1.085258 \n",
      "\n",
      "Loss: 1.153309 [   64/60000]\n",
      "Loss: 1.157708 [ 6464/60000]\n",
      "Loss: 0.978782 [12864/60000]\n",
      "Loss: 1.109835 [19264/60000]\n",
      "Loss: 0.987317 [25664/60000]\n",
      "Loss: 1.011517 [32064/60000]\n",
      "Loss: 1.064913 [38464/60000]\n",
      "Loss: 0.988832 [44864/60000]\n",
      "Loss: 1.029301 [51264/60000]\n",
      "Loss: 0.959252 [57664/60000]\n",
      "Test error: \n",
      " Accuracy: 65.8%, Avg loss: 0.974837 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01b958",
   "metadata": {},
   "source": [
    "# Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "962640dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to ..\\..\\models\\01_00_model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"..\\\\..\\\\models\\\\01_00_model.pth\")\n",
    "print(\"Saved PyTorch Model State to ..\\\\..\\\\models\\\\01_00_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4006e2",
   "metadata": {},
   "source": [
    "# Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93ed2944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"..\\\\..\\\\models\\\\01_00_model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ba113b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 'Ankle boot', Actual: 'Ankle boot'\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f\"Predicted: '{predicted}', Actual: '{actual}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
